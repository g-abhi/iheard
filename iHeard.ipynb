{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iHeard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "542540d7b3f14e56aa43955c53a2bc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a98cdf1728d4ff3b88c05a61e85b7b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbbd5e87a9fc4053aacdc771cdc4b633",
              "IPY_MODEL_60d1f59e79b343838c389a33b979be74"
            ]
          }
        },
        "7a98cdf1728d4ff3b88c05a61e85b7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbbd5e87a9fc4053aacdc771cdc4b633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6e82dd1f1214f7dab4e27c50ab570ea",
            "_dom_classes": [],
            "description": "  4%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08aef1523cac49048aadeb3bfe36c5ca"
          }
        },
        "60d1f59e79b343838c389a33b979be74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edb65defdb184b7094dc3aec955884ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 227852288/6023741708 [1:05:48&lt;27:54:07, 57700.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_966365ed43df4e3e93ab62f5c0a15e1c"
          }
        },
        "d6e82dd1f1214f7dab4e27c50ab570ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08aef1523cac49048aadeb3bfe36c5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edb65defdb184b7094dc3aec955884ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "966365ed43df4e3e93ab62f5c0a15e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCZKsVGXHji_"
      },
      "source": [
        "**Downloading and Initializing Required Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRspHwwE7qgf",
        "outputId": "c2bf35eb-156e-480f-efd3-b926b34d69e9"
      },
      "source": [
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu101 in /usr/local/lib/python3.6/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu101 in /usr/local/lib/python3.6/dist-packages (0.8.2+cu101)\n",
            "Requirement already satisfied: torchaudio==0.7.2 in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.2+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAGCMEhrw57C",
        "outputId": "74c89171-c369-4598-fc03-6bb54c4b29bf"
      },
      "source": [
        "!pip install soundfile\n",
        "!pip install librosa\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.19.4)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (51.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6pbLiRP8w-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fd6323-4092-4b96-b8db-682d1f7a38f2"
      },
      "source": [
        "# imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets.utils import download_url as download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import csv\n",
        "import soundfile\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KeUmcrc-2f1",
        "outputId": "3b23776f-0f05-4fbf-9689-8ac796895799"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390,
          "referenced_widgets": [
            "542540d7b3f14e56aa43955c53a2bc42",
            "7a98cdf1728d4ff3b88c05a61e85b7b9",
            "fbbd5e87a9fc4053aacdc771cdc4b633",
            "60d1f59e79b343838c389a33b979be74",
            "d6e82dd1f1214f7dab4e27c50ab570ea",
            "08aef1523cac49048aadeb3bfe36c5ca",
            "edb65defdb184b7094dc3aec955884ab",
            "966365ed43df4e3e93ab62f5c0a15e1c"
          ]
        },
        "id": "yhXNcIEw9ANu",
        "outputId": "caf93a7d-f70e-4dbb-803c-27ade71cefab"
      },
      "source": [
        "# Downloads dataset to google drive, will have to manually rename the file to UrbanSound8K.tar.gz\n",
        "dataset_url = 'https://goo.gl/8hY5ER'\n",
        "download_url(dataset_url, \"/tmp/gdrive/My Drive/urban_data/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://goo.gl/8hY5ER to /tmp/gdrive/My Drive/urban_data/8hY5ER\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "542540d7b3f14e56aa43955c53a2bc42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d86da4c0ed74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Downloads dataset to google drive, will have to manually rename the file to UrbanSound8K.tar.gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://goo.gl/8hY5ER'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/tmp/gdrive/My Drive/urban_data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     70\u001b[0m             urllib.request.urlretrieve(\n\u001b[1;32m     71\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_bar_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             )\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRSx34Xi_cWK"
      },
      "source": [
        "with tarfile.open(\"/tmp/gdrive/MyDrive/urban_data/UrbanSound8K.tar.gz\", mode = 'r:gz') as tar:\n",
        "    tar.extractall(path='/tmp/gdrive/MyDrive/urban_data/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQbaBYhsHrok"
      },
      "source": [
        "**Formatting and Cleaning Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xgZEjcUaGAD"
      },
      "source": [
        "with open(\"/content/gdrive/MyDrive/urban_data/data/UrbanSound8K/metadata/UrbanSound8K.csv\") as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEJIPq-bFc0B",
        "outputId": "d0c73cdc-b973-43bf-fedf-5e326017f412"
      },
      "source": [
        "# explains the different categories of data available\n",
        "data_dir = \"/content/gdrive/MyDrive/urban_data/data/UrbanSound8K\"\n",
        "print(os.listdir(data_dir))\n",
        "print(os.listdir(data_dir+\"/metadata\"))\n",
        "print(os.listdir(data_dir+\"/audio\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.DS_Store', 'audio', 'FREESOUNDCREDITS.txt', 'metadata', 'UrbanSound8K_README.txt']\n",
            "['.DS_Store', 'UrbanSound8K.csv']\n",
            "['.DS_Store', 'fold1', 'fold10', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNqYgK6zFx5j",
        "outputId": "5e57beab-431f-4ec5-d55c-8ab62d1b6cba"
      },
      "source": [
        "# viewing the information about each song from the dataset using pandas\n",
        "csvData = pd.read_csv(data_dir+\"/metadata/UrbanSound8K.csv\")\n",
        "print(len(list(csvData.iloc))) # total number of songs we are dealing with\n",
        "print(csvData.iloc[0]) # exmaple of a an object in the csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8732\n",
            "slice_file_name    100032-3-0-0.wav\n",
            "fsID                         100032\n",
            "start                             0\n",
            "end                        0.317551\n",
            "salience                          1\n",
            "fold                              5\n",
            "classID                           3\n",
            "class                      dog_bark\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDRRop4wQg6U"
      },
      "source": [
        "**Defining the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z4Aie6jPQlwM",
        "outputId": "947340f8-c059-4d06-b5b2-5f0e58271088"
      },
      "source": [
        "torchaudio.set_audio_backend(\"sox_io\")\n",
        "torchaudio.get_audio_backend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sox_io'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlkS5tNgxNMX",
        "outputId": "ed5c325e-d1e1-4dc8-bbed-03acd7547e88"
      },
      "source": [
        "soundfile.available_subtypes('FLAC')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PCM_16': 'Signed 16 bit PCM',\n",
              " 'PCM_24': 'Signed 24 bit PCM',\n",
              " 'PCM_S8': 'Signed 8 bit PCM'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLu7lzrwi5gj"
      },
      "source": [
        "class UrbanSounds(Dataset):\n",
        "    def __init__(self, csv_file_path, folders_file_path, seed=10, sample_size = 176400):\n",
        "        \"\"\"\n",
        "        :param csv_file_path: Path to the csv file with metadata about sounds\n",
        "        :param folders_file_path: Path to directory housing folders with\n",
        "        :param seed: Specifies which folder number to be used to test data-performance\n",
        "        :param sample_size: Specifies how big the audio samples should be (bigger is better, but requires more time and data)\n",
        "        \"\"\"\n",
        "        self.urban_sounds_frame = pd.read_csv(csv_file_path)\n",
        "        self.folders_file_path = folders_file_path\n",
        "\n",
        "        self.sound_id_name = {\n",
        "            0: \"air_conditioner\",\n",
        "            1: \"car_horn\",\n",
        "            2: \"children_playing\",\n",
        "            3: \"dog_bark\",\n",
        "            4: \"drilling\",\n",
        "            5: \"engine_idling\",\n",
        "            6: \"gun_shot\",\n",
        "            7: \"jackhammer\",\n",
        "            8: \"siren\",\n",
        "            9: \"street_music\"\n",
        "        }\n",
        "\n",
        "        self.sample_size = sample_size\n",
        "        self.seed = seed\n",
        "\n",
        "        self.train_ds = []\n",
        "        self.test_ds = []\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Setup iloc\n",
        "        slicer = self.urban_sounds_frame.iloc\n",
        "        wav_unit = slicer[index]\n",
        "\n",
        "        # Find the folder number, name, and classifcation associated with the index\n",
        "        wav_name = wav_unit[\"slice_file_name\"]\n",
        "        wav_fold = wav_unit[\"fold\"]\n",
        "        wav_classid = wav_unit[\"classID\"]\n",
        "        wav_classname = self.sound_id_name[wav_classid]\n",
        "\n",
        "        # Get the wav file using the path\n",
        "        wav_file = self.folders_file_path + \"/fold\"+str(wav_fold)+\"/\"+wav_name\n",
        "\n",
        "        # Convert bit depth to 32 bit\n",
        "        data, samplerate = librosa.load(wav_file, 44100, mono=True)\n",
        "        sound = torch.from_numpy(data)\n",
        "\n",
        "        # Convert the wav file to a tensor\n",
        "        # tensors, default_sample_rate = torchaudio.load(wav_file)\n",
        "        # print(samplerate, tensors.shape)\n",
        "\n",
        "        # OPTIONAL MIXING (Uncomment for the mixing to work, otherwise expect 2 channel audio)\n",
        "        # sound = torch.mean(tensors, dim=0, keepdim=True)\n",
        "\n",
        "        # Fix all wav files to 176400 samples\n",
        "        padded_data = torch.zeros(176400) #tempData accounts for audio clips that are too short\n",
        "\n",
        "        if sound.numel() < 176400:\n",
        "            padded_data[:sound.numel()] = sound[:]\n",
        "        else:\n",
        "            padded_data[:] = sound[:176400]\n",
        "        \n",
        "\n",
        "        final_data = torch.zeros(self.sample_size)\n",
        "        every_n = 176400 // self.sample_size\n",
        "\n",
        "        count = 0\n",
        "        for i in range(self.sample_size):\n",
        "            final_data[i] = padded_data[count]\n",
        "            count += every_n\n",
        "        \n",
        "        return (final_data, wav_fold, wav_classid)\n",
        "    \n",
        "    def set_train_test(self):\n",
        "        for i in tqdm(range(8372)):\n",
        "            (tensor, folder, classID) = self[i]\n",
        "            if int(folder) == self.seed:\n",
        "                self.test_ds.append((tensor, classID))\n",
        "            else:\n",
        "                self.train_ds.append((tensor, classID))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.urban_sounds_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEIoYaVogSW_",
        "outputId": "ef84910c-0844-4a27-e9fe-f29beea216a6"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC2A6ZhUjm1i"
      },
      "source": [
        "dataset = UrbanSounds(csv_file_path=\"/tmp/gdrive/MyDrive/urban_data/data/UrbanSound8K/metadata/UrbanSound8K.csv\", folders_file_path=\"/tmp/gdrive/MyDrive/urban_data/data/UrbanSound8K/audio\", sample_size=32000)\n",
        "# dataset.set_train_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmYgHGGTxGVI"
      },
      "source": [
        "import pickle\n",
        "with open('train_ds.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset.train_ds, f)\n",
        "with open('test_ds.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset.test_ds, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4QiWgJxzkwZ"
      },
      "source": [
        "import pickle\n",
        "dataset.train_ds = None\n",
        "with open('train_ds.pkl', 'rb') as f:\n",
        "    dataset.train_ds = pickle.load(f)\n",
        "\n",
        "dataset.test_set = None\n",
        "with open('test_ds.pkl', 'rb') as f:\n",
        "    dataset.test_ds = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O2nzTLu9xRA",
        "outputId": "c131716e-74a0-4432-bee7-e4657e923fc6"
      },
      "source": [
        "print(len(dataset.train_ds))\n",
        "print(len(dataset.test_ds))\n",
        "\n",
        "batch_size = 128\n",
        "train_dl = DataLoader(dataset.train_ds, batch_size, shuffle=True)\n",
        "test_dl = DataLoader(dataset.test_ds, batch_size*2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7583\n",
            "789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuxkD-7JWO50"
      },
      "source": [
        "class Permute(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.permute(0, 2, 1)\n",
        "        \n",
        "class Unsqueeze(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.unsqueeze(1)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            Unsqueeze(),\n",
        "\n",
        "            nn.Conv1d(1, 64, 80, 5),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(4),\n",
        "\n",
        "            nn.Conv1d(64, 64, 3),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, 3),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(4),\n",
        "\n",
        "            nn.Conv1d(64, 128, 3),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 128, 3),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(4),\n",
        "\n",
        "            nn.Conv1d(128, 256, 3),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(256, 256, 3),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(256, 256, 3),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(4),\n",
        "\n",
        "            nn.Conv1d(256, 512, 3),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(512, 512, 3),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.AvgPool1d(19),\n",
        "            Permute(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=2)\n",
        "            )\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xs5yvIolimQ",
        "outputId": "1ac9ebd0-0715-46ed-f9fd-13faeee8b660"
      },
      "source": [
        "model = Net()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (network): Sequential(\n",
              "    (0): Unsqueeze()\n",
              "    (1): Conv1d(1, 64, kernel_size=(80,), stride=(5,))\n",
              "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
              "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU()\n",
              "    (8): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
              "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
              "    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU()\n",
              "    (15): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
              "    (16): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU()\n",
              "    (18): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
              "    (20): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (21): ReLU()\n",
              "    (22): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
              "    (23): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU()\n",
              "    (25): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
              "    (26): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU()\n",
              "    (28): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (29): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
              "    (30): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (31): ReLU()\n",
              "    (32): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
              "    (33): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (34): ReLU()\n",
              "    (35): AvgPool1d(kernel_size=(19,), stride=(19,), padding=(0,))\n",
              "    (36): Permute()\n",
              "    (37): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (38): LogSoftmax(dim=2)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqjb_LwhP1R-"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFA6ORH3P4MA"
      },
      "source": [
        "def train(model, epoch):\n",
        "    model.train() # change the mode of the model\n",
        "    for batch_idx, (data, target) in enumerate(train_dl):\n",
        "        optimizer.zero_grad()\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        data = data.requires_grad_() #set requires_grad to True for training\n",
        "        output = model(data)\n",
        "        output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x10 \n",
        "        loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_dl.dataset),\n",
        "        100. * batch_idx / len(train_dl), loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yrr5pi9QS3i"
      },
      "source": [
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in test_dl:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        output = output.permute(1, 0, 2)\n",
        "        pred = output.max(2)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target).cpu().sum().item()\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(test_dl.dataset),\n",
        "        100. * correct / len(test_dl.dataset)))\n",
        "    return (1. * correct / len(test_dl.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twl6g4Sq-Z_d",
        "outputId": "294d9650-b738-41a0-f3ef-066cbf151069"
      },
      "source": [
        "log_interval = 20\n",
        "counter = 0\n",
        "history = []\n",
        "for epoch in range(300):\n",
        "    if epoch > 99 and epoch % 100 == 0:\n",
        "        print((epoch//100), \"round of training complete. Dividing learning rate by 10\")\n",
        "    scheduler.step()\n",
        "    train(model, epoch)\n",
        "    acc = test(model, epoch)\n",
        "\n",
        "    history.append((epoch, acc * 100))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [1829/7583 (98%)]\tLoss: 0.396829\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 1 [1829/7583 (98%)]\tLoss: 0.837211\n",
            "\n",
            "Test set: Accuracy: 457/789 (58%)\n",
            "\n",
            "Train Epoch: 2 [1829/7583 (98%)]\tLoss: 0.583222\n",
            "\n",
            "Test set: Accuracy: 454/789 (58%)\n",
            "\n",
            "Train Epoch: 3 [1829/7583 (98%)]\tLoss: 0.533040\n",
            "\n",
            "Test set: Accuracy: 473/789 (60%)\n",
            "\n",
            "Train Epoch: 4 [1829/7583 (98%)]\tLoss: 0.932074\n",
            "\n",
            "Test set: Accuracy: 384/789 (49%)\n",
            "\n",
            "Train Epoch: 5 [1829/7583 (98%)]\tLoss: 0.627020\n",
            "\n",
            "Test set: Accuracy: 476/789 (60%)\n",
            "\n",
            "Train Epoch: 6 [1829/7583 (98%)]\tLoss: 0.512309\n",
            "\n",
            "Test set: Accuracy: 478/789 (61%)\n",
            "\n",
            "Train Epoch: 7 [1829/7583 (98%)]\tLoss: 0.699526\n",
            "\n",
            "Test set: Accuracy: 435/789 (55%)\n",
            "\n",
            "Train Epoch: 8 [1829/7583 (98%)]\tLoss: 0.735817\n",
            "\n",
            "Test set: Accuracy: 458/789 (58%)\n",
            "\n",
            "Train Epoch: 9 [1829/7583 (98%)]\tLoss: 0.626046\n",
            "\n",
            "Test set: Accuracy: 445/789 (56%)\n",
            "\n",
            "Train Epoch: 10 [1829/7583 (98%)]\tLoss: 0.520502\n",
            "\n",
            "Test set: Accuracy: 408/789 (52%)\n",
            "\n",
            "Train Epoch: 11 [1829/7583 (98%)]\tLoss: 0.268406\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 12 [1829/7583 (98%)]\tLoss: 0.452541\n",
            "\n",
            "Test set: Accuracy: 415/789 (53%)\n",
            "\n",
            "Train Epoch: 13 [1829/7583 (98%)]\tLoss: 0.415976\n",
            "\n",
            "Test set: Accuracy: 546/789 (69%)\n",
            "\n",
            "Train Epoch: 14 [1829/7583 (98%)]\tLoss: 0.560108\n",
            "\n",
            "Test set: Accuracy: 438/789 (56%)\n",
            "\n",
            "Train Epoch: 15 [1829/7583 (98%)]\tLoss: 0.888896\n",
            "\n",
            "Test set: Accuracy: 510/789 (65%)\n",
            "\n",
            "Train Epoch: 16 [1829/7583 (98%)]\tLoss: 0.528589\n",
            "\n",
            "Test set: Accuracy: 474/789 (60%)\n",
            "\n",
            "Train Epoch: 17 [1829/7583 (98%)]\tLoss: 0.754546\n",
            "\n",
            "Test set: Accuracy: 386/789 (49%)\n",
            "\n",
            "Train Epoch: 18 [1829/7583 (98%)]\tLoss: 1.202896\n",
            "\n",
            "Test set: Accuracy: 444/789 (56%)\n",
            "\n",
            "Train Epoch: 19 [1829/7583 (98%)]\tLoss: 0.341446\n",
            "\n",
            "Test set: Accuracy: 494/789 (63%)\n",
            "\n",
            "Train Epoch: 20 [1829/7583 (98%)]\tLoss: 0.198552\n",
            "\n",
            "Test set: Accuracy: 358/789 (45%)\n",
            "\n",
            "Train Epoch: 21 [1829/7583 (98%)]\tLoss: 0.600576\n",
            "\n",
            "Test set: Accuracy: 392/789 (50%)\n",
            "\n",
            "Train Epoch: 22 [1829/7583 (98%)]\tLoss: 0.547598\n",
            "\n",
            "Test set: Accuracy: 455/789 (58%)\n",
            "\n",
            "Train Epoch: 23 [1829/7583 (98%)]\tLoss: 0.295342\n",
            "\n",
            "Test set: Accuracy: 404/789 (51%)\n",
            "\n",
            "Train Epoch: 24 [1829/7583 (98%)]\tLoss: 0.387947\n",
            "\n",
            "Test set: Accuracy: 496/789 (63%)\n",
            "\n",
            "Train Epoch: 25 [1829/7583 (98%)]\tLoss: 0.973921\n",
            "\n",
            "Test set: Accuracy: 394/789 (50%)\n",
            "\n",
            "Train Epoch: 26 [1829/7583 (98%)]\tLoss: 0.740477\n",
            "\n",
            "Test set: Accuracy: 483/789 (61%)\n",
            "\n",
            "Train Epoch: 27 [1829/7583 (98%)]\tLoss: 0.753338\n",
            "\n",
            "Test set: Accuracy: 398/789 (50%)\n",
            "\n",
            "Train Epoch: 28 [1829/7583 (98%)]\tLoss: 0.289161\n",
            "\n",
            "Test set: Accuracy: 431/789 (55%)\n",
            "\n",
            "Train Epoch: 29 [1829/7583 (98%)]\tLoss: 0.277224\n",
            "\n",
            "Test set: Accuracy: 438/789 (56%)\n",
            "\n",
            "Train Epoch: 30 [1829/7583 (98%)]\tLoss: 0.262064\n",
            "\n",
            "Test set: Accuracy: 424/789 (54%)\n",
            "\n",
            "Train Epoch: 31 [1829/7583 (98%)]\tLoss: 0.615408\n",
            "\n",
            "Test set: Accuracy: 469/789 (59%)\n",
            "\n",
            "Train Epoch: 32 [1829/7583 (98%)]\tLoss: 0.533768\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 33 [1829/7583 (98%)]\tLoss: 0.246464\n",
            "\n",
            "Test set: Accuracy: 446/789 (57%)\n",
            "\n",
            "Train Epoch: 34 [1829/7583 (98%)]\tLoss: 0.416156\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 35 [1829/7583 (98%)]\tLoss: 0.610081\n",
            "\n",
            "Test set: Accuracy: 476/789 (60%)\n",
            "\n",
            "Train Epoch: 36 [1829/7583 (98%)]\tLoss: 0.515315\n",
            "\n",
            "Test set: Accuracy: 448/789 (57%)\n",
            "\n",
            "Train Epoch: 37 [1829/7583 (98%)]\tLoss: 0.440939\n",
            "\n",
            "Test set: Accuracy: 421/789 (53%)\n",
            "\n",
            "Train Epoch: 38 [1829/7583 (98%)]\tLoss: 0.905167\n",
            "\n",
            "Test set: Accuracy: 451/789 (57%)\n",
            "\n",
            "Train Epoch: 39 [1829/7583 (98%)]\tLoss: 0.315864\n",
            "\n",
            "Test set: Accuracy: 481/789 (61%)\n",
            "\n",
            "Train Epoch: 40 [1829/7583 (98%)]\tLoss: 0.372669\n",
            "\n",
            "Test set: Accuracy: 470/789 (60%)\n",
            "\n",
            "Train Epoch: 41 [1829/7583 (98%)]\tLoss: 0.783551\n",
            "\n",
            "Test set: Accuracy: 407/789 (52%)\n",
            "\n",
            "Train Epoch: 42 [1829/7583 (98%)]\tLoss: 0.858255\n",
            "\n",
            "Test set: Accuracy: 469/789 (59%)\n",
            "\n",
            "Train Epoch: 43 [1829/7583 (98%)]\tLoss: 0.316459\n",
            "\n",
            "Test set: Accuracy: 469/789 (59%)\n",
            "\n",
            "Train Epoch: 44 [1829/7583 (98%)]\tLoss: 0.517457\n",
            "\n",
            "Test set: Accuracy: 434/789 (55%)\n",
            "\n",
            "Train Epoch: 45 [1829/7583 (98%)]\tLoss: 0.188958\n",
            "\n",
            "Test set: Accuracy: 492/789 (62%)\n",
            "\n",
            "Train Epoch: 46 [1829/7583 (98%)]\tLoss: 0.081474\n",
            "\n",
            "Test set: Accuracy: 455/789 (58%)\n",
            "\n",
            "Train Epoch: 47 [1829/7583 (98%)]\tLoss: 0.349524\n",
            "\n",
            "Test set: Accuracy: 417/789 (53%)\n",
            "\n",
            "Train Epoch: 48 [1829/7583 (98%)]\tLoss: 0.631781\n",
            "\n",
            "Test set: Accuracy: 413/789 (52%)\n",
            "\n",
            "Train Epoch: 49 [1829/7583 (98%)]\tLoss: 0.363003\n",
            "\n",
            "Test set: Accuracy: 511/789 (65%)\n",
            "\n",
            "Train Epoch: 50 [1829/7583 (98%)]\tLoss: 0.274457\n",
            "\n",
            "Test set: Accuracy: 492/789 (62%)\n",
            "\n",
            "Train Epoch: 51 [1829/7583 (98%)]\tLoss: 0.063976\n",
            "\n",
            "Test set: Accuracy: 458/789 (58%)\n",
            "\n",
            "Train Epoch: 52 [1829/7583 (98%)]\tLoss: 0.527553\n",
            "\n",
            "Test set: Accuracy: 454/789 (58%)\n",
            "\n",
            "Train Epoch: 53 [1829/7583 (98%)]\tLoss: 0.576464\n",
            "\n",
            "Test set: Accuracy: 410/789 (52%)\n",
            "\n",
            "Train Epoch: 54 [1829/7583 (98%)]\tLoss: 0.286296\n",
            "\n",
            "Test set: Accuracy: 492/789 (62%)\n",
            "\n",
            "Train Epoch: 55 [1829/7583 (98%)]\tLoss: 0.718017\n",
            "\n",
            "Test set: Accuracy: 434/789 (55%)\n",
            "\n",
            "Train Epoch: 56 [1829/7583 (98%)]\tLoss: 0.634227\n",
            "\n",
            "Test set: Accuracy: 382/789 (48%)\n",
            "\n",
            "Train Epoch: 57 [1829/7583 (98%)]\tLoss: 0.358487\n",
            "\n",
            "Test set: Accuracy: 417/789 (53%)\n",
            "\n",
            "Train Epoch: 58 [1829/7583 (98%)]\tLoss: 0.455198\n",
            "\n",
            "Test set: Accuracy: 381/789 (48%)\n",
            "\n",
            "Train Epoch: 59 [1829/7583 (98%)]\tLoss: 0.218060\n",
            "\n",
            "Test set: Accuracy: 410/789 (52%)\n",
            "\n",
            "Train Epoch: 60 [1829/7583 (98%)]\tLoss: 0.381367\n",
            "\n",
            "Test set: Accuracy: 478/789 (61%)\n",
            "\n",
            "Train Epoch: 61 [1829/7583 (98%)]\tLoss: 0.406755\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 62 [1829/7583 (98%)]\tLoss: 0.123452\n",
            "\n",
            "Test set: Accuracy: 450/789 (57%)\n",
            "\n",
            "Train Epoch: 63 [1829/7583 (98%)]\tLoss: 0.168679\n",
            "\n",
            "Test set: Accuracy: 466/789 (59%)\n",
            "\n",
            "Train Epoch: 64 [1829/7583 (98%)]\tLoss: 0.357236\n",
            "\n",
            "Test set: Accuracy: 454/789 (58%)\n",
            "\n",
            "Train Epoch: 65 [1829/7583 (98%)]\tLoss: 0.279545\n",
            "\n",
            "Test set: Accuracy: 472/789 (60%)\n",
            "\n",
            "Train Epoch: 66 [1829/7583 (98%)]\tLoss: 0.732948\n",
            "\n",
            "Test set: Accuracy: 476/789 (60%)\n",
            "\n",
            "Train Epoch: 67 [1829/7583 (98%)]\tLoss: 0.132802\n",
            "\n",
            "Test set: Accuracy: 462/789 (59%)\n",
            "\n",
            "Train Epoch: 68 [1829/7583 (98%)]\tLoss: 0.899048\n",
            "\n",
            "Test set: Accuracy: 420/789 (53%)\n",
            "\n",
            "Train Epoch: 69 [1829/7583 (98%)]\tLoss: 0.401323\n",
            "\n",
            "Test set: Accuracy: 415/789 (53%)\n",
            "\n",
            "Train Epoch: 70 [1829/7583 (98%)]\tLoss: 0.708711\n",
            "\n",
            "Test set: Accuracy: 489/789 (62%)\n",
            "\n",
            "Train Epoch: 71 [1829/7583 (98%)]\tLoss: 0.479021\n",
            "\n",
            "Test set: Accuracy: 470/789 (60%)\n",
            "\n",
            "Train Epoch: 72 [1829/7583 (98%)]\tLoss: 0.342845\n",
            "\n",
            "Test set: Accuracy: 484/789 (61%)\n",
            "\n",
            "Train Epoch: 73 [1829/7583 (98%)]\tLoss: 0.408706\n",
            "\n",
            "Test set: Accuracy: 422/789 (53%)\n",
            "\n",
            "Train Epoch: 74 [1829/7583 (98%)]\tLoss: 0.191577\n",
            "\n",
            "Test set: Accuracy: 431/789 (55%)\n",
            "\n",
            "Train Epoch: 75 [1829/7583 (98%)]\tLoss: 0.357016\n",
            "\n",
            "Test set: Accuracy: 437/789 (55%)\n",
            "\n",
            "Train Epoch: 76 [1829/7583 (98%)]\tLoss: 0.378996\n",
            "\n",
            "Test set: Accuracy: 399/789 (51%)\n",
            "\n",
            "Train Epoch: 77 [1829/7583 (98%)]\tLoss: 0.568071\n",
            "\n",
            "Test set: Accuracy: 428/789 (54%)\n",
            "\n",
            "Train Epoch: 78 [1829/7583 (98%)]\tLoss: 0.647622\n",
            "\n",
            "Test set: Accuracy: 482/789 (61%)\n",
            "\n",
            "Train Epoch: 79 [1829/7583 (98%)]\tLoss: 0.266470\n",
            "\n",
            "Test set: Accuracy: 481/789 (61%)\n",
            "\n",
            "Train Epoch: 80 [1829/7583 (98%)]\tLoss: 0.354425\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 81 [1829/7583 (98%)]\tLoss: 0.307789\n",
            "\n",
            "Test set: Accuracy: 494/789 (63%)\n",
            "\n",
            "Train Epoch: 82 [1829/7583 (98%)]\tLoss: 0.220565\n",
            "\n",
            "Test set: Accuracy: 471/789 (60%)\n",
            "\n",
            "Train Epoch: 83 [1829/7583 (98%)]\tLoss: 0.364337\n",
            "\n",
            "Test set: Accuracy: 452/789 (57%)\n",
            "\n",
            "Train Epoch: 84 [1829/7583 (98%)]\tLoss: 0.593809\n",
            "\n",
            "Test set: Accuracy: 452/789 (57%)\n",
            "\n",
            "Train Epoch: 85 [1829/7583 (98%)]\tLoss: 0.499492\n",
            "\n",
            "Test set: Accuracy: 396/789 (50%)\n",
            "\n",
            "Train Epoch: 86 [1829/7583 (98%)]\tLoss: 0.468949\n",
            "\n",
            "Test set: Accuracy: 475/789 (60%)\n",
            "\n",
            "Train Epoch: 87 [1829/7583 (98%)]\tLoss: 0.358892\n",
            "\n",
            "Test set: Accuracy: 502/789 (64%)\n",
            "\n",
            "Train Epoch: 88 [1829/7583 (98%)]\tLoss: 0.413035\n",
            "\n",
            "Test set: Accuracy: 447/789 (57%)\n",
            "\n",
            "Train Epoch: 89 [1829/7583 (98%)]\tLoss: 0.084403\n",
            "\n",
            "Test set: Accuracy: 402/789 (51%)\n",
            "\n",
            "Train Epoch: 90 [1829/7583 (98%)]\tLoss: 0.501249\n",
            "\n",
            "Test set: Accuracy: 503/789 (64%)\n",
            "\n",
            "Train Epoch: 91 [1829/7583 (98%)]\tLoss: 0.336660\n",
            "\n",
            "Test set: Accuracy: 522/789 (66%)\n",
            "\n",
            "Train Epoch: 92 [1829/7583 (98%)]\tLoss: 0.105165\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 93 [1829/7583 (98%)]\tLoss: 0.606994\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 94 [1829/7583 (98%)]\tLoss: 0.310082\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 95 [1829/7583 (98%)]\tLoss: 0.083241\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 96 [1829/7583 (98%)]\tLoss: 0.052277\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 97 [1829/7583 (98%)]\tLoss: 0.259859\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 98 [1829/7583 (98%)]\tLoss: 0.330584\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 99 [1829/7583 (98%)]\tLoss: 0.034591\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "1 round of training complete. Dividing learning rate by 10\n",
            "Train Epoch: 100 [1829/7583 (98%)]\tLoss: 0.077754\n",
            "\n",
            "Test set: Accuracy: 506/789 (64%)\n",
            "\n",
            "Train Epoch: 101 [1829/7583 (98%)]\tLoss: 0.079078\n",
            "\n",
            "Test set: Accuracy: 511/789 (65%)\n",
            "\n",
            "Train Epoch: 102 [1829/7583 (98%)]\tLoss: 0.174537\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 103 [1829/7583 (98%)]\tLoss: 0.022308\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 104 [1829/7583 (98%)]\tLoss: 0.089414\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 105 [1829/7583 (98%)]\tLoss: 0.012431\n",
            "\n",
            "Test set: Accuracy: 509/789 (65%)\n",
            "\n",
            "Train Epoch: 106 [1829/7583 (98%)]\tLoss: 0.105991\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 107 [1829/7583 (98%)]\tLoss: 0.124287\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 108 [1829/7583 (98%)]\tLoss: 0.105252\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 109 [1829/7583 (98%)]\tLoss: 0.430987\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 110 [1829/7583 (98%)]\tLoss: 0.096370\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 111 [1829/7583 (98%)]\tLoss: 0.195198\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 112 [1829/7583 (98%)]\tLoss: 0.020644\n",
            "\n",
            "Test set: Accuracy: 529/789 (67%)\n",
            "\n",
            "Train Epoch: 113 [1829/7583 (98%)]\tLoss: 0.247940\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 114 [1829/7583 (98%)]\tLoss: 0.071044\n",
            "\n",
            "Test set: Accuracy: 511/789 (65%)\n",
            "\n",
            "Train Epoch: 115 [1829/7583 (98%)]\tLoss: 0.102481\n",
            "\n",
            "Test set: Accuracy: 528/789 (67%)\n",
            "\n",
            "Train Epoch: 116 [1829/7583 (98%)]\tLoss: 0.026421\n",
            "\n",
            "Test set: Accuracy: 527/789 (67%)\n",
            "\n",
            "Train Epoch: 117 [1829/7583 (98%)]\tLoss: 0.431285\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 118 [1829/7583 (98%)]\tLoss: 0.299169\n",
            "\n",
            "Test set: Accuracy: 538/789 (68%)\n",
            "\n",
            "Train Epoch: 119 [1829/7583 (98%)]\tLoss: 0.056582\n",
            "\n",
            "Test set: Accuracy: 531/789 (67%)\n",
            "\n",
            "Train Epoch: 120 [1829/7583 (98%)]\tLoss: 0.173989\n",
            "\n",
            "Test set: Accuracy: 531/789 (67%)\n",
            "\n",
            "Train Epoch: 121 [1829/7583 (98%)]\tLoss: 0.273572\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 122 [1829/7583 (98%)]\tLoss: 0.106725\n",
            "\n",
            "Test set: Accuracy: 547/789 (69%)\n",
            "\n",
            "Train Epoch: 123 [1829/7583 (98%)]\tLoss: 0.163126\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 124 [1829/7583 (98%)]\tLoss: 0.050557\n",
            "\n",
            "Test set: Accuracy: 529/789 (67%)\n",
            "\n",
            "Train Epoch: 125 [1829/7583 (98%)]\tLoss: 0.066334\n",
            "\n",
            "Test set: Accuracy: 535/789 (68%)\n",
            "\n",
            "Train Epoch: 126 [1829/7583 (98%)]\tLoss: 0.001856\n",
            "\n",
            "Test set: Accuracy: 537/789 (68%)\n",
            "\n",
            "Train Epoch: 127 [1829/7583 (98%)]\tLoss: 0.067688\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 128 [1829/7583 (98%)]\tLoss: 0.033272\n",
            "\n",
            "Test set: Accuracy: 529/789 (67%)\n",
            "\n",
            "Train Epoch: 129 [1829/7583 (98%)]\tLoss: 0.028104\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 130 [1829/7583 (98%)]\tLoss: 0.031013\n",
            "\n",
            "Test set: Accuracy: 536/789 (68%)\n",
            "\n",
            "Train Epoch: 131 [1829/7583 (98%)]\tLoss: 0.035238\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 132 [1829/7583 (98%)]\tLoss: 0.251244\n",
            "\n",
            "Test set: Accuracy: 542/789 (69%)\n",
            "\n",
            "Train Epoch: 133 [1829/7583 (98%)]\tLoss: 0.012159\n",
            "\n",
            "Test set: Accuracy: 535/789 (68%)\n",
            "\n",
            "Train Epoch: 134 [1829/7583 (98%)]\tLoss: 0.049577\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 135 [1829/7583 (98%)]\tLoss: 0.189921\n",
            "\n",
            "Test set: Accuracy: 520/789 (66%)\n",
            "\n",
            "Train Epoch: 136 [1829/7583 (98%)]\tLoss: 0.065732\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 137 [1829/7583 (98%)]\tLoss: 0.094543\n",
            "\n",
            "Test set: Accuracy: 530/789 (67%)\n",
            "\n",
            "Train Epoch: 138 [1829/7583 (98%)]\tLoss: 0.142159\n",
            "\n",
            "Test set: Accuracy: 522/789 (66%)\n",
            "\n",
            "Train Epoch: 139 [1829/7583 (98%)]\tLoss: 0.246375\n",
            "\n",
            "Test set: Accuracy: 529/789 (67%)\n",
            "\n",
            "Train Epoch: 140 [1829/7583 (98%)]\tLoss: 0.139515\n",
            "\n",
            "Test set: Accuracy: 549/789 (70%)\n",
            "\n",
            "Train Epoch: 141 [1829/7583 (98%)]\tLoss: 0.034778\n",
            "\n",
            "Test set: Accuracy: 535/789 (68%)\n",
            "\n",
            "Train Epoch: 142 [1829/7583 (98%)]\tLoss: 0.026360\n",
            "\n",
            "Test set: Accuracy: 548/789 (69%)\n",
            "\n",
            "Train Epoch: 143 [1829/7583 (98%)]\tLoss: 0.145528\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 144 [1829/7583 (98%)]\tLoss: 0.015024\n",
            "\n",
            "Test set: Accuracy: 537/789 (68%)\n",
            "\n",
            "Train Epoch: 145 [1829/7583 (98%)]\tLoss: 0.139592\n",
            "\n",
            "Test set: Accuracy: 528/789 (67%)\n",
            "\n",
            "Train Epoch: 146 [1829/7583 (98%)]\tLoss: 0.038319\n",
            "\n",
            "Test set: Accuracy: 502/789 (64%)\n",
            "\n",
            "Train Epoch: 147 [1829/7583 (98%)]\tLoss: 0.428179\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 148 [1829/7583 (98%)]\tLoss: 0.098641\n",
            "\n",
            "Test set: Accuracy: 511/789 (65%)\n",
            "\n",
            "Train Epoch: 149 [1829/7583 (98%)]\tLoss: 0.411356\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 150 [1829/7583 (98%)]\tLoss: 0.127797\n",
            "\n",
            "Test set: Accuracy: 512/789 (65%)\n",
            "\n",
            "Train Epoch: 151 [1829/7583 (98%)]\tLoss: 0.050505\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 152 [1829/7583 (98%)]\tLoss: 0.030301\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 153 [1829/7583 (98%)]\tLoss: 0.009782\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 154 [1829/7583 (98%)]\tLoss: 0.046672\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 155 [1829/7583 (98%)]\tLoss: 0.016227\n",
            "\n",
            "Test set: Accuracy: 522/789 (66%)\n",
            "\n",
            "Train Epoch: 156 [1829/7583 (98%)]\tLoss: 0.019981\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 157 [1829/7583 (98%)]\tLoss: 0.045499\n",
            "\n",
            "Test set: Accuracy: 539/789 (68%)\n",
            "\n",
            "Train Epoch: 158 [1829/7583 (98%)]\tLoss: 0.163492\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 159 [1829/7583 (98%)]\tLoss: 0.119080\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 160 [1829/7583 (98%)]\tLoss: 0.213595\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 161 [1829/7583 (98%)]\tLoss: 0.157875\n",
            "\n",
            "Test set: Accuracy: 555/789 (70%)\n",
            "\n",
            "Train Epoch: 162 [1829/7583 (98%)]\tLoss: 0.198597\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 163 [1829/7583 (98%)]\tLoss: 0.023176\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 164 [1829/7583 (98%)]\tLoss: 0.105190\n",
            "\n",
            "Test set: Accuracy: 536/789 (68%)\n",
            "\n",
            "Train Epoch: 165 [1829/7583 (98%)]\tLoss: 0.075404\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 166 [1829/7583 (98%)]\tLoss: 0.160897\n",
            "\n",
            "Test set: Accuracy: 494/789 (63%)\n",
            "\n",
            "Train Epoch: 167 [1829/7583 (98%)]\tLoss: 0.036130\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 168 [1829/7583 (98%)]\tLoss: 0.006655\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 169 [1829/7583 (98%)]\tLoss: 0.102480\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 170 [1829/7583 (98%)]\tLoss: 0.281314\n",
            "\n",
            "Test set: Accuracy: 539/789 (68%)\n",
            "\n",
            "Train Epoch: 171 [1829/7583 (98%)]\tLoss: 0.029030\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 172 [1829/7583 (98%)]\tLoss: 0.112857\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 173 [1829/7583 (98%)]\tLoss: 0.140150\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 174 [1829/7583 (98%)]\tLoss: 0.156556\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 175 [1829/7583 (98%)]\tLoss: 0.064362\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 176 [1829/7583 (98%)]\tLoss: 0.042311\n",
            "\n",
            "Test set: Accuracy: 488/789 (62%)\n",
            "\n",
            "Train Epoch: 177 [1829/7583 (98%)]\tLoss: 0.136779\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 178 [1829/7583 (98%)]\tLoss: 0.026170\n",
            "\n",
            "Test set: Accuracy: 528/789 (67%)\n",
            "\n",
            "Train Epoch: 179 [1829/7583 (98%)]\tLoss: 0.052007\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 180 [1829/7583 (98%)]\tLoss: 0.041007\n",
            "\n",
            "Test set: Accuracy: 536/789 (68%)\n",
            "\n",
            "Train Epoch: 181 [1829/7583 (98%)]\tLoss: 0.315615\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 182 [1829/7583 (98%)]\tLoss: 0.138464\n",
            "\n",
            "Test set: Accuracy: 536/789 (68%)\n",
            "\n",
            "Train Epoch: 183 [1829/7583 (98%)]\tLoss: 0.015979\n",
            "\n",
            "Test set: Accuracy: 512/789 (65%)\n",
            "\n",
            "Train Epoch: 184 [1829/7583 (98%)]\tLoss: 0.072328\n",
            "\n",
            "Test set: Accuracy: 509/789 (65%)\n",
            "\n",
            "Train Epoch: 185 [1829/7583 (98%)]\tLoss: 0.077701\n",
            "\n",
            "Test set: Accuracy: 533/789 (68%)\n",
            "\n",
            "Train Epoch: 186 [1829/7583 (98%)]\tLoss: 0.099895\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 187 [1829/7583 (98%)]\tLoss: 0.052245\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 188 [1829/7583 (98%)]\tLoss: 0.075641\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 189 [1829/7583 (98%)]\tLoss: 0.435774\n",
            "\n",
            "Test set: Accuracy: 494/789 (63%)\n",
            "\n",
            "Train Epoch: 190 [1829/7583 (98%)]\tLoss: 0.285603\n",
            "\n",
            "Test set: Accuracy: 538/789 (68%)\n",
            "\n",
            "Train Epoch: 191 [1829/7583 (98%)]\tLoss: 0.036451\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 192 [1829/7583 (98%)]\tLoss: 0.224665\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 193 [1829/7583 (98%)]\tLoss: 0.010757\n",
            "\n",
            "Test set: Accuracy: 528/789 (67%)\n",
            "\n",
            "Train Epoch: 194 [1829/7583 (98%)]\tLoss: 0.410497\n",
            "\n",
            "Test set: Accuracy: 520/789 (66%)\n",
            "\n",
            "Train Epoch: 195 [1829/7583 (98%)]\tLoss: 0.065865\n",
            "\n",
            "Test set: Accuracy: 527/789 (67%)\n",
            "\n",
            "Train Epoch: 196 [1829/7583 (98%)]\tLoss: 0.157762\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 197 [1829/7583 (98%)]\tLoss: 0.024184\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 198 [1829/7583 (98%)]\tLoss: 0.050220\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 199 [1829/7583 (98%)]\tLoss: 0.062027\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "2 round of training complete. Dividing learning rate by 10\n",
            "Train Epoch: 200 [1829/7583 (98%)]\tLoss: 0.045938\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 201 [1829/7583 (98%)]\tLoss: 0.002168\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 202 [1829/7583 (98%)]\tLoss: 0.036326\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 203 [1829/7583 (98%)]\tLoss: 0.056834\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 204 [1829/7583 (98%)]\tLoss: 0.011679\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 205 [1829/7583 (98%)]\tLoss: 0.006969\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 206 [1829/7583 (98%)]\tLoss: 0.205847\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 207 [1829/7583 (98%)]\tLoss: 0.424894\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 208 [1829/7583 (98%)]\tLoss: 0.009284\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 209 [1829/7583 (98%)]\tLoss: 0.015651\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 210 [1829/7583 (98%)]\tLoss: 0.015415\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 211 [1829/7583 (98%)]\tLoss: 0.019466\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 212 [1829/7583 (98%)]\tLoss: 0.046673\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 213 [1829/7583 (98%)]\tLoss: 0.239502\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 214 [1829/7583 (98%)]\tLoss: 0.247892\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 215 [1829/7583 (98%)]\tLoss: 0.029843\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 216 [1829/7583 (98%)]\tLoss: 0.180990\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 217 [1829/7583 (98%)]\tLoss: 0.206574\n",
            "\n",
            "Test set: Accuracy: 520/789 (66%)\n",
            "\n",
            "Train Epoch: 218 [1829/7583 (98%)]\tLoss: 0.112507\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 219 [1829/7583 (98%)]\tLoss: 0.032664\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 220 [1829/7583 (98%)]\tLoss: 0.036152\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 221 [1829/7583 (98%)]\tLoss: 0.185718\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 222 [1829/7583 (98%)]\tLoss: 0.109267\n",
            "\n",
            "Test set: Accuracy: 537/789 (68%)\n",
            "\n",
            "Train Epoch: 223 [1829/7583 (98%)]\tLoss: 0.263078\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 224 [1829/7583 (98%)]\tLoss: 0.165529\n",
            "\n",
            "Test set: Accuracy: 528/789 (67%)\n",
            "\n",
            "Train Epoch: 225 [1829/7583 (98%)]\tLoss: 0.227979\n",
            "\n",
            "Test set: Accuracy: 531/789 (67%)\n",
            "\n",
            "Train Epoch: 226 [1829/7583 (98%)]\tLoss: 0.441517\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 227 [1829/7583 (98%)]\tLoss: 0.021954\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 228 [1829/7583 (98%)]\tLoss: 0.462448\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 229 [1829/7583 (98%)]\tLoss: 0.477536\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 230 [1829/7583 (98%)]\tLoss: 0.129124\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 231 [1829/7583 (98%)]\tLoss: 0.007764\n",
            "\n",
            "Test set: Accuracy: 509/789 (65%)\n",
            "\n",
            "Train Epoch: 232 [1829/7583 (98%)]\tLoss: 0.051608\n",
            "\n",
            "Test set: Accuracy: 509/789 (65%)\n",
            "\n",
            "Train Epoch: 233 [1829/7583 (98%)]\tLoss: 0.065212\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 234 [1829/7583 (98%)]\tLoss: 0.009194\n",
            "\n",
            "Test set: Accuracy: 530/789 (67%)\n",
            "\n",
            "Train Epoch: 235 [1829/7583 (98%)]\tLoss: 0.048792\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 236 [1829/7583 (98%)]\tLoss: 0.443944\n",
            "\n",
            "Test set: Accuracy: 532/789 (67%)\n",
            "\n",
            "Train Epoch: 237 [1829/7583 (98%)]\tLoss: 0.012404\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 238 [1829/7583 (98%)]\tLoss: 0.029633\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 239 [1829/7583 (98%)]\tLoss: 0.015595\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 240 [1829/7583 (98%)]\tLoss: 0.008988\n",
            "\n",
            "Test set: Accuracy: 510/789 (65%)\n",
            "\n",
            "Train Epoch: 241 [1829/7583 (98%)]\tLoss: 0.279217\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 242 [1829/7583 (98%)]\tLoss: 0.127890\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 243 [1829/7583 (98%)]\tLoss: 0.185591\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 244 [1829/7583 (98%)]\tLoss: 0.003571\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 245 [1829/7583 (98%)]\tLoss: 0.152203\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 246 [1829/7583 (98%)]\tLoss: 0.059544\n",
            "\n",
            "Test set: Accuracy: 510/789 (65%)\n",
            "\n",
            "Train Epoch: 247 [1829/7583 (98%)]\tLoss: 0.227753\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 248 [1829/7583 (98%)]\tLoss: 0.250371\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 249 [1829/7583 (98%)]\tLoss: 0.154616\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 250 [1829/7583 (98%)]\tLoss: 0.204352\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 251 [1829/7583 (98%)]\tLoss: 0.009161\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 252 [1829/7583 (98%)]\tLoss: 0.008275\n",
            "\n",
            "Test set: Accuracy: 512/789 (65%)\n",
            "\n",
            "Train Epoch: 253 [1829/7583 (98%)]\tLoss: 0.044350\n",
            "\n",
            "Test set: Accuracy: 522/789 (66%)\n",
            "\n",
            "Train Epoch: 254 [1829/7583 (98%)]\tLoss: 0.051252\n",
            "\n",
            "Test set: Accuracy: 511/789 (65%)\n",
            "\n",
            "Train Epoch: 255 [1829/7583 (98%)]\tLoss: 0.055242\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 256 [1829/7583 (98%)]\tLoss: 0.052480\n",
            "\n",
            "Test set: Accuracy: 509/789 (65%)\n",
            "\n",
            "Train Epoch: 257 [1829/7583 (98%)]\tLoss: 0.023238\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 258 [1829/7583 (98%)]\tLoss: 0.025456\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 259 [1829/7583 (98%)]\tLoss: 0.103843\n",
            "\n",
            "Test set: Accuracy: 512/789 (65%)\n",
            "\n",
            "Train Epoch: 260 [1829/7583 (98%)]\tLoss: 0.009237\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 261 [1829/7583 (98%)]\tLoss: 0.164984\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 262 [1829/7583 (98%)]\tLoss: 0.001461\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 263 [1829/7583 (98%)]\tLoss: 0.511620\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 264 [1829/7583 (98%)]\tLoss: 0.020681\n",
            "\n",
            "Test set: Accuracy: 530/789 (67%)\n",
            "\n",
            "Train Epoch: 265 [1829/7583 (98%)]\tLoss: 0.021737\n",
            "\n",
            "Test set: Accuracy: 530/789 (67%)\n",
            "\n",
            "Train Epoch: 266 [1829/7583 (98%)]\tLoss: 0.272307\n",
            "\n",
            "Test set: Accuracy: 528/789 (67%)\n",
            "\n",
            "Train Epoch: 267 [1829/7583 (98%)]\tLoss: 0.073027\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 268 [1829/7583 (98%)]\tLoss: 0.194825\n",
            "\n",
            "Test set: Accuracy: 530/789 (67%)\n",
            "\n",
            "Train Epoch: 269 [1829/7583 (98%)]\tLoss: 0.017471\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 270 [1829/7583 (98%)]\tLoss: 0.079474\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 271 [1829/7583 (98%)]\tLoss: 0.018235\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 272 [1829/7583 (98%)]\tLoss: 0.058144\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 273 [1829/7583 (98%)]\tLoss: 0.010847\n",
            "\n",
            "Test set: Accuracy: 513/789 (65%)\n",
            "\n",
            "Train Epoch: 274 [1829/7583 (98%)]\tLoss: 0.044397\n",
            "\n",
            "Test set: Accuracy: 530/789 (67%)\n",
            "\n",
            "Train Epoch: 275 [1829/7583 (98%)]\tLoss: 0.529941\n",
            "\n",
            "Test set: Accuracy: 534/789 (68%)\n",
            "\n",
            "Train Epoch: 276 [1829/7583 (98%)]\tLoss: 0.010669\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 277 [1829/7583 (98%)]\tLoss: 0.127405\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 278 [1829/7583 (98%)]\tLoss: 0.126957\n",
            "\n",
            "Test set: Accuracy: 523/789 (66%)\n",
            "\n",
            "Train Epoch: 279 [1829/7583 (98%)]\tLoss: 0.005721\n",
            "\n",
            "Test set: Accuracy: 520/789 (66%)\n",
            "\n",
            "Train Epoch: 280 [1829/7583 (98%)]\tLoss: 0.081499\n",
            "\n",
            "Test set: Accuracy: 539/789 (68%)\n",
            "\n",
            "Train Epoch: 281 [1829/7583 (98%)]\tLoss: 0.153089\n",
            "\n",
            "Test set: Accuracy: 525/789 (67%)\n",
            "\n",
            "Train Epoch: 282 [1829/7583 (98%)]\tLoss: 0.042532\n",
            "\n",
            "Test set: Accuracy: 526/789 (67%)\n",
            "\n",
            "Train Epoch: 283 [1829/7583 (98%)]\tLoss: 0.056685\n",
            "\n",
            "Test set: Accuracy: 520/789 (66%)\n",
            "\n",
            "Train Epoch: 284 [1829/7583 (98%)]\tLoss: 0.153711\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 285 [1829/7583 (98%)]\tLoss: 0.009067\n",
            "\n",
            "Test set: Accuracy: 519/789 (66%)\n",
            "\n",
            "Train Epoch: 286 [1829/7583 (98%)]\tLoss: 0.329741\n",
            "\n",
            "Test set: Accuracy: 510/789 (65%)\n",
            "\n",
            "Train Epoch: 287 [1829/7583 (98%)]\tLoss: 0.005462\n",
            "\n",
            "Test set: Accuracy: 508/789 (64%)\n",
            "\n",
            "Train Epoch: 288 [1829/7583 (98%)]\tLoss: 0.006938\n",
            "\n",
            "Test set: Accuracy: 515/789 (65%)\n",
            "\n",
            "Train Epoch: 289 [1829/7583 (98%)]\tLoss: 0.135158\n",
            "\n",
            "Test set: Accuracy: 521/789 (66%)\n",
            "\n",
            "Train Epoch: 290 [1829/7583 (98%)]\tLoss: 0.008804\n",
            "\n",
            "Test set: Accuracy: 518/789 (66%)\n",
            "\n",
            "Train Epoch: 291 [1829/7583 (98%)]\tLoss: 0.097873\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 292 [1829/7583 (98%)]\tLoss: 0.265614\n",
            "\n",
            "Test set: Accuracy: 524/789 (66%)\n",
            "\n",
            "Train Epoch: 293 [1829/7583 (98%)]\tLoss: 0.068003\n",
            "\n",
            "Test set: Accuracy: 511/789 (65%)\n",
            "\n",
            "Train Epoch: 294 [1829/7583 (98%)]\tLoss: 0.053651\n",
            "\n",
            "Test set: Accuracy: 514/789 (65%)\n",
            "\n",
            "Train Epoch: 295 [1829/7583 (98%)]\tLoss: 0.026821\n",
            "\n",
            "Test set: Accuracy: 512/789 (65%)\n",
            "\n",
            "Train Epoch: 296 [1829/7583 (98%)]\tLoss: 0.021220\n",
            "\n",
            "Test set: Accuracy: 506/789 (64%)\n",
            "\n",
            "Train Epoch: 297 [1829/7583 (98%)]\tLoss: 0.156651\n",
            "\n",
            "Test set: Accuracy: 517/789 (66%)\n",
            "\n",
            "Train Epoch: 298 [1829/7583 (98%)]\tLoss: 0.012465\n",
            "\n",
            "Test set: Accuracy: 516/789 (65%)\n",
            "\n",
            "Train Epoch: 299 [1829/7583 (98%)]\tLoss: 0.064234\n",
            "\n",
            "Test set: Accuracy: 510/789 (65%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "CGO74xJR3sCQ",
        "outputId": "808da426-c476-468e-9881-074a9505bf46"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.clf()\n",
        "print(history)\n",
        "y_val = [x[1] for x in history]\n",
        "x_val = [x[0] for x in history]\n",
        "plt.plot(y_val)\n",
        "\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Percentage Accuracy')\n",
        "plt.ylim(0, 100)\n",
        "plt.title('Percentage Accuracy for Deep Learning Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, 66.41318124207858), (1, 57.92141951837769), (2, 57.54119138149556), (3, 59.949302915082384), (4, 48.669201520912544), (5, 60.329531051964516), (6, 60.5830164765526), (7, 55.13307984790875), (8, 58.04816223067174), (9, 56.40050697084917), (10, 51.71102661596958), (11, 64.38529784537388), (12, 52.59822560202788), (13, 69.20152091254754), (14, 55.51330798479087), (15, 64.63878326996198), (16, 60.07604562737643), (17, 48.92268694550063), (18, 56.27376425855514), (19, 62.61089987325729), (20, 45.373891001267424), (21, 49.68314321926489), (22, 57.66793409378961), (23, 51.20405576679341), (24, 62.864385297845374), (25, 49.93662864385298), (26, 61.21673003802282), (27, 50.44359949302915), (28, 54.62610899873257), (29, 55.51330798479087), (30, 53.73891001267427), (31, 59.442332065906214), (32, 64.38529784537388), (33, 56.527249683143225), (34, 65.65272496831433), (35, 60.329531051964516), (36, 56.7807351077313), (37, 53.35868187579214), (38, 57.16096324461344), (39, 60.96324461343473), (40, 59.569074778200246), (41, 51.58428390367554), (42, 59.442332065906214), (43, 59.442332065906214), (44, 55.0063371356147), (45, 62.3574144486692), (46, 57.66793409378961), (47, 52.851711026615966), (48, 52.344740177439796), (49, 64.76552598225602), (50, 62.3574144486692), (51, 58.04816223067174), (52, 57.54119138149556), (53, 51.964512040557665), (54, 62.3574144486692), (55, 55.0063371356147), (56, 48.41571609632446), (57, 52.851711026615966), (58, 48.28897338403042), (59, 51.964512040557665), (60, 60.5830164765526), (61, 64.38529784537388), (62, 57.03422053231939), (63, 59.062103929024076), (64, 57.54119138149556), (65, 59.822560202788345), (66, 60.329531051964516), (67, 58.55513307984791), (68, 53.2319391634981), (69, 52.59822560202788), (70, 61.97718631178707), (71, 59.569074778200246), (72, 61.34347275031685), (73, 53.48542458808618), (74, 54.62610899873257), (75, 55.38656527249684), (76, 50.57034220532319), (77, 54.24588086185045), (78, 61.08998732572877), (79, 60.96324461343473), (80, 67.42712294043093), (81, 62.61089987325729), (82, 59.6958174904943), (83, 57.28770595690747), (84, 57.28770595690747), (85, 50.19011406844106), (86, 60.20278833967046), (87, 63.624841571609636), (88, 56.65399239543726), (89, 50.950570342205324), (90, 63.751584283903675), (91, 66.15969581749049), (92, 66.66666666666666), (93, 66.03295310519644), (94, 65.27249683143219), (95, 65.39923954372624), (96, 65.39923954372624), (97, 65.77946768060836), (98, 65.0190114068441), (99, 65.52598225602027), (100, 64.1318124207858), (101, 64.76552598225602), (102, 65.27249683143219), (103, 64.38529784537388), (104, 65.0190114068441), (105, 64.51204055766794), (106, 65.39923954372624), (107, 65.65272496831433), (108, 65.27249683143219), (109, 65.52598225602027), (110, 66.28643852978455), (111, 67.68060836501901), (112, 67.0468948035488), (113, 66.66666666666666), (114, 64.76552598225602), (115, 66.92015209125475), (116, 66.79340937896072), (117, 66.41318124207858), (118, 68.18757921419518), (119, 67.30038022813687), (120, 67.30038022813687), (121, 67.68060836501901), (122, 69.32826362484157), (123, 67.68060836501901), (124, 67.0468948035488), (125, 67.80735107731304), (126, 68.06083650190115), (127, 66.66666666666666), (128, 67.0468948035488), (129, 67.68060836501901), (130, 67.9340937896071), (131, 66.66666666666666), (132, 68.69455006337135), (133, 67.80735107731304), (134, 67.42712294043093), (135, 65.90621039290241), (136, 65.65272496831433), (137, 67.17363751584284), (138, 66.15969581749049), (139, 67.0468948035488), (140, 69.58174904942965), (141, 67.80735107731304), (142, 69.45500633713561), (143, 66.28643852978455), (144, 68.06083650190115), (145, 66.92015209125475), (146, 63.624841571609636), (147, 66.41318124207858), (148, 64.76552598225602), (149, 67.42712294043093), (150, 64.89226869455005), (151, 66.53992395437263), (152, 66.03295310519644), (153, 66.28643852978455), (154, 65.52598225602027), (155, 66.15969581749049), (156, 65.27249683143219), (157, 68.31432192648923), (158, 66.53992395437263), (159, 65.14575411913816), (160, 65.0190114068441), (161, 70.34220532319392), (162, 66.53992395437263), (163, 66.53992395437263), (164, 67.9340937896071), (165, 65.27249683143219), (166, 62.61089987325729), (167, 66.66666666666666), (168, 66.03295310519644), (169, 66.53992395437263), (170, 68.31432192648923), (171, 65.14575411913816), (172, 66.66666666666666), (173, 65.14575411913816), (174, 65.0190114068441), (175, 65.0190114068441), (176, 61.85044359949303), (177, 66.28643852978455), (178, 66.92015209125475), (179, 66.03295310519644), (180, 67.9340937896071), (181, 65.39923954372624), (182, 67.9340937896071), (183, 64.89226869455005), (184, 64.51204055766794), (185, 67.55386565272497), (186, 67.42712294043093), (187, 65.52598225602027), (188, 67.68060836501901), (189, 62.61089987325729), (190, 68.18757921419518), (191, 66.28643852978455), (192, 66.66666666666666), (193, 66.92015209125475), (194, 65.90621039290241), (195, 66.79340937896072), (196, 66.53992395437263), (197, 66.53992395437263), (198, 66.66666666666666), (199, 65.77946768060836), (200, 66.03295310519644), (201, 65.77946768060836), (202, 65.39923954372624), (203, 65.77946768060836), (204, 66.53992395437263), (205, 65.65272496831433), (206, 65.27249683143219), (207, 65.14575411913816), (208, 66.03295310519644), (209, 66.28643852978455), (210, 65.39923954372624), (211, 65.65272496831433), (212, 65.65272496831433), (213, 65.27249683143219), (214, 64.38529784537388), (215, 65.14575411913816), (216, 65.27249683143219), (217, 65.90621039290241), (218, 65.39923954372624), (219, 65.65272496831433), (220, 65.14575411913816), (221, 65.52598225602027), (222, 68.06083650190115), (223, 67.42712294043093), (224, 66.92015209125475), (225, 67.30038022813687), (226, 67.42712294043093), (227, 65.0190114068441), (228, 66.03295310519644), (229, 65.14575411913816), (230, 65.77946768060836), (231, 64.51204055766794), (232, 64.51204055766794), (233, 65.0190114068441), (234, 67.17363751584284), (235, 66.41318124207858), (236, 67.42712294043093), (237, 66.41318124207858), (238, 65.14575411913816), (239, 65.14575411913816), (240, 64.63878326996198), (241, 64.38529784537388), (242, 65.0190114068441), (243, 65.0190114068441), (244, 67.68060836501901), (245, 65.14575411913816), (246, 64.63878326996198), (247, 66.66666666666666), (248, 65.77946768060836), (249, 65.52598225602027), (250, 65.14575411913816), (251, 65.52598225602027), (252, 64.89226869455005), (253, 66.15969581749049), (254, 64.76552598225602), (255, 65.52598225602027), (256, 64.51204055766794), (257, 65.14575411913816), (258, 64.38529784537388), (259, 64.89226869455005), (260, 65.27249683143219), (261, 65.65272496831433), (262, 66.66666666666666), (263, 66.41318124207858), (264, 67.17363751584284), (265, 67.17363751584284), (266, 66.92015209125475), (267, 66.03295310519644), (268, 67.17363751584284), (269, 66.53992395437263), (270, 66.53992395437263), (271, 65.65272496831433), (272, 65.77946768060836), (273, 65.0190114068441), (274, 67.17363751584284), (275, 67.68060836501901), (276, 66.28643852978455), (277, 66.41318124207858), (278, 66.28643852978455), (279, 65.90621039290241), (280, 68.31432192648923), (281, 66.53992395437263), (282, 66.66666666666666), (283, 65.90621039290241), (284, 65.65272496831433), (285, 65.77946768060836), (286, 64.63878326996198), (287, 64.38529784537388), (288, 65.27249683143219), (289, 66.03295310519644), (290, 65.65272496831433), (291, 65.52598225602027), (292, 66.41318124207858), (293, 64.76552598225602), (294, 65.14575411913816), (295, 64.89226869455005), (296, 64.1318124207858), (297, 65.52598225602027), (298, 65.39923954372624), (299, 64.63878326996198)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hRew-3Ov-w2"
      },
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHXNw0L9L6X"
      },
      "source": [
        "torch.save(model.state_dict(), 'deep_net.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlfShW2d9T89"
      },
      "source": [
        "# Loading model\n",
        "# model = to_device(Net(), device)\n",
        "# model.load_state_dict(torch.load('cifar10-cnn.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}